{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['color', 'director_name', 'num_critic_for_reviews', 'duration', 'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name', 'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name', 'movie_title', 'num_voted_users', 'cast_total_facebook_likes', 'actor_3_name', 'facenumber_in_poster', 'plot_keywords', 'movie_imdb_link', 'num_user_for_reviews', 'language', 'country', 'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes', 'imdb_score', 'aspect_ratio', 'movie_facebook_likes']\n",
      "2698\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "NUM_THRESHOLDS = 5\n",
    "\n",
    "#reads in the data\n",
    "data = pd.read_csv('movie_metadata.csv')\n",
    "print(list(data))\n",
    "print(data.isnull().sum().sum())\n",
    "#removes the values that aren't numeric\n",
    "to_drop = ['director_name', 'num_critic_for_reviews', 'actor_2_name','actor_1_name', 'movie_title', 'num_voted_users'\n",
    "           , 'actor_3_name', 'plot_keywords', 'movie_imdb_link', 'num_user_for_reviews']\n",
    "\n",
    "#makes the new data set without the to_drop colums\n",
    "features_list = data.columns.difference(to_drop)\n",
    "movie_data = data[features_list]\n",
    "#print(np.sum(movie_num.isnull()))\n",
    "#print(movie_data.content_rating.unique())\n",
    "pd.options.mode.chained_assignment = None \n",
    "   \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing Genres into individual Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['Sci-Fi', 'Crime', 'Romance', 'Animation', 'Music', 'Comedy', 'War', 'Horror', 'Film-Noir', 'Adventure', 'News', 'Reality-TV', 'Thriller', 'Western', 'Mystery', 'Short', 'Drama', 'Action', 'Documentary', 'Musical', 'History', 'Family', 'Fantasy', 'Game-Show', 'Sport', 'Biography'])\n"
     ]
    }
   ],
   "source": [
    "# make a set with all unique genres\n",
    "\n",
    "genres = []\n",
    "\n",
    "for string in movie_data['genres']:\n",
    "    genre = string.split('|')\n",
    "    genres = genres+genre\n",
    "    \n",
    "genres_set = set(genres)\n",
    "print(genres_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "genres_dict = dict()\n",
    "for genre in genres_set:\n",
    "    genres_dict[genre] = []\n",
    "    \n",
    "for string in movie_data.genres:\n",
    "    genres = string.split('|')\n",
    "    for genre in genres_set:\n",
    "        if genre in genres:\n",
    "            genres_dict[genre] = genres_dict[genre]+[1]\n",
    "        else:\n",
    "            genres_dict[genre] = genres_dict[genre]+[0]\n",
    "\n",
    "del movie_data['genres']\n",
    "#print(genres_dict['Short'])\n",
    "\n",
    "for genre in genres_set:\n",
    "    series = pd.Series(genres_dict[genre])\n",
    "    movie_data[genre] = series\n",
    "\n",
    "#print(movie_data['Short'].values)    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting NaN's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting number of NaNs per threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length before deletion: 5043\n",
      "       actor_1_facebook_likes  actor_2_facebook_likes  actor_3_facebook_likes  \\\n",
      "count             3771.000000             3771.000000             3771.000000   \n",
      "mean              7722.743039             2014.861575              768.953328   \n",
      "std              15495.082232             4537.226690             1890.902126   \n",
      "min                  0.000000                0.000000                0.000000   \n",
      "25%                744.000000              381.000000              192.000000   \n",
      "50%               1000.000000              683.000000              434.000000   \n",
      "75%              13000.000000              975.500000              690.000000   \n",
      "max             640000.000000           137000.000000            23000.000000   \n",
      "\n",
      "       aspect_ratio        budget  cast_total_facebook_likes  \\\n",
      "count   3771.000000  3.771000e+03                3771.000000   \n",
      "mean       2.111114  4.607467e+07               11486.958632   \n",
      "std        0.352759  2.255753e+08               19094.928984   \n",
      "min        1.180000  2.180000e+02                   0.000000   \n",
      "25%        1.850000  1.000000e+07                1903.500000   \n",
      "50%        2.350000  2.500000e+07                4039.000000   \n",
      "75%        2.350000  5.000000e+07               16227.500000   \n",
      "max       16.000000  1.221550e+10              656730.000000   \n",
      "\n",
      "       director_facebook_likes     duration  facenumber_in_poster  \\\n",
      "count              3771.000000  3771.000000           3771.000000   \n",
      "mean                804.246354   110.219570              1.377088   \n",
      "std                3062.453302    22.629024              2.041076   \n",
      "min                   0.000000    37.000000              0.000000   \n",
      "25%                  11.000000    96.000000              0.000000   \n",
      "50%                  63.000000   106.000000              1.000000   \n",
      "75%                 235.000000   120.000000              2.000000   \n",
      "max               23000.000000   330.000000             43.000000   \n",
      "\n",
      "              gross     ...             Drama       Action  Documentary  \\\n",
      "count  3.771000e+03     ...       3771.000000  3771.000000  3771.000000   \n",
      "mean   5.241037e+07     ...          0.504906     0.254574     0.012464   \n",
      "std    7.025137e+07     ...          0.500042     0.435679     0.110957   \n",
      "min    1.620000e+02     ...          0.000000     0.000000     0.000000   \n",
      "25%    8.075214e+06     ...          0.000000     0.000000     0.000000   \n",
      "50%    3.001299e+07     ...          1.000000     0.000000     0.000000   \n",
      "75%    6.670553e+07     ...          1.000000     1.000000     0.000000   \n",
      "max    7.605058e+08     ...          1.000000     1.000000     1.000000   \n",
      "\n",
      "           Musical      History       Family      Fantasy  Game-Show  \\\n",
      "count  3771.000000  3771.000000  3771.000000  3771.000000     3771.0   \n",
      "mean      0.025457     0.039512     0.117475     0.134712        0.0   \n",
      "std       0.157531     0.194836     0.322029     0.341461        0.0   \n",
      "min       0.000000     0.000000     0.000000     0.000000        0.0   \n",
      "25%       0.000000     0.000000     0.000000     0.000000        0.0   \n",
      "50%       0.000000     0.000000     0.000000     0.000000        0.0   \n",
      "75%       0.000000     0.000000     0.000000     0.000000        0.0   \n",
      "max       1.000000     1.000000     1.000000     1.000000        0.0   \n",
      "\n",
      "             Sport    Biography  \n",
      "count  3771.000000  3771.000000  \n",
      "mean      0.039247     0.063909  \n",
      "std       0.194208     0.244623  \n",
      "min       0.000000     0.000000  \n",
      "25%       0.000000     0.000000  \n",
      "50%       0.000000     0.000000  \n",
      "75%       0.000000     0.000000  \n",
      "max       1.000000     1.000000  \n",
      "\n",
      "[8 rows x 39 columns]\n",
      "Length after deletion: 3771\n",
      "Length before deletion: 5043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/anaconda2/lib/python2.7/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       actor_1_facebook_likes  actor_2_facebook_likes  actor_3_facebook_likes  \\\n",
      "count             4490.000000              4490.00000             4486.000000   \n",
      "mean              7032.598886              1792.34922              691.491083   \n",
      "std              14773.131343              4229.70189             1745.970390   \n",
      "min                  0.000000                 0.00000                0.000000   \n",
      "25%                673.250000               326.00000                     NaN   \n",
      "50%               1000.000000               636.00000                     NaN   \n",
      "75%              12000.000000               943.75000                     NaN   \n",
      "max             640000.000000            137000.00000            23000.000000   \n",
      "\n",
      "       aspect_ratio        budget  cast_total_facebook_likes  \\\n",
      "count   4436.000000  4.268000e+03                4490.000000   \n",
      "mean       2.109612  4.184082e+07               10423.809800   \n",
      "std        0.544585  2.124521e+08               18131.415354   \n",
      "min        1.180000  2.180000e+02                   0.000000   \n",
      "25%             NaN           NaN                1620.250000   \n",
      "50%             NaN           NaN                3452.500000   \n",
      "75%             NaN           NaN               14902.000000   \n",
      "max       16.000000  1.221550e+10              656730.000000   \n",
      "\n",
      "       director_facebook_likes     duration  facenumber_in_poster  \\\n",
      "count              4490.000000  4490.000000           4485.000000   \n",
      "mean                744.864588   109.241425              1.355407   \n",
      "std                2928.918234    22.390797              2.013086   \n",
      "min                   0.000000    20.000000              0.000000   \n",
      "25%                   9.000000    95.000000                   NaN   \n",
      "50%                  56.000000   105.000000                   NaN   \n",
      "75%                 218.000000   119.000000                   NaN   \n",
      "max               23000.000000   330.000000             43.000000   \n",
      "\n",
      "              gross     ...             Drama       Action  Documentary  \\\n",
      "count  4.086000e+03     ...       4490.000000  4490.000000  4490.000000   \n",
      "mean   4.928752e+07     ...          0.512918     0.236526     0.017149   \n",
      "std    6.877173e+07     ...          0.499889     0.424996     0.129842   \n",
      "min    1.620000e+02     ...          0.000000     0.000000     0.000000   \n",
      "25%             NaN     ...          0.000000     0.000000     0.000000   \n",
      "50%             NaN     ...          1.000000     0.000000     0.000000   \n",
      "75%             NaN     ...          1.000000     0.000000     0.000000   \n",
      "max    7.605058e+08     ...          1.000000     1.000000     1.000000   \n",
      "\n",
      "           Musical      History       Family      Fantasy  Game-Show  \\\n",
      "count  4490.000000  4490.000000  4490.000000  4490.000000     4490.0   \n",
      "mean      0.026726     0.042094     0.109577     0.126058        0.0   \n",
      "std       0.161300     0.200825     0.312396     0.331952        0.0   \n",
      "min       0.000000     0.000000     0.000000     0.000000        0.0   \n",
      "25%       0.000000     0.000000     0.000000     0.000000        0.0   \n",
      "50%       0.000000     0.000000     0.000000     0.000000        0.0   \n",
      "75%       0.000000     0.000000     0.000000     0.000000        0.0   \n",
      "max       1.000000     1.000000     1.000000     1.000000        0.0   \n",
      "\n",
      "             Sport    Biography  \n",
      "count  4490.000000  4490.000000  \n",
      "mean      0.038530     0.061470  \n",
      "std       0.192494     0.240217  \n",
      "min       0.000000     0.000000  \n",
      "25%       0.000000     0.000000  \n",
      "50%       0.000000     0.000000  \n",
      "75%       0.000000     0.000000  \n",
      "max       1.000000     1.000000  \n",
      "\n",
      "[8 rows x 39 columns]\n",
      "Length after deletion: 4490\n",
      "Length before deletion: 5043\n",
      "       actor_1_facebook_likes  actor_2_facebook_likes  actor_3_facebook_likes  \\\n",
      "count             4777.000000             4776.000000             4770.000000   \n",
      "mean              6747.996860             1713.497069              664.698323   \n",
      "std              14452.754208             4127.438726             1704.630166   \n",
      "min                  0.000000                0.000000                0.000000   \n",
      "25%                634.000000                     NaN                     NaN   \n",
      "50%               1000.000000                     NaN                     NaN   \n",
      "75%              11000.000000                     NaN                     NaN   \n",
      "max             640000.000000           137000.000000            23000.000000   \n",
      "\n",
      "       aspect_ratio        budget  cast_total_facebook_likes  \\\n",
      "count   4600.000000  4.458000e+03                4777.000000   \n",
      "mean       2.117743  4.044427e+07               10003.110111   \n",
      "std        0.676869  2.081812e+08               17758.157505   \n",
      "min        1.180000  2.180000e+02                   0.000000   \n",
      "25%             NaN           NaN                1491.000000   \n",
      "50%             NaN           NaN                3218.000000   \n",
      "75%             NaN           NaN               14420.000000   \n",
      "max       16.000000  1.221550e+10              656730.000000   \n",
      "\n",
      "       director_facebook_likes     duration  facenumber_in_poster  \\\n",
      "count              4777.000000  4776.000000           4767.000000   \n",
      "mean                703.776847   108.555276              1.364800   \n",
      "std                2844.415717    22.504112              2.007676   \n",
      "min                   0.000000     7.000000              0.000000   \n",
      "25%                   8.000000          NaN                   NaN   \n",
      "50%                  52.000000          NaN                   NaN   \n",
      "75%                 209.000000          NaN                   NaN   \n",
      "max               23000.000000   330.000000             43.000000   \n",
      "\n",
      "              gross     ...             Drama       Action  Documentary  \\\n",
      "count  4.146000e+03     ...       4777.000000  4777.000000  4777.000000   \n",
      "mean   4.861944e+07     ...          0.512665     0.232154     0.020096   \n",
      "std    6.850699e+07     ...          0.499892     0.422251     0.140344   \n",
      "min    1.620000e+02     ...          0.000000     0.000000     0.000000   \n",
      "25%             NaN     ...          0.000000     0.000000     0.000000   \n",
      "50%             NaN     ...          1.000000     0.000000     0.000000   \n",
      "75%             NaN     ...          1.000000     0.000000     0.000000   \n",
      "max    7.605058e+08     ...          1.000000     1.000000     1.000000   \n",
      "\n",
      "           Musical      History       Family      Fantasy  Game-Show  \\\n",
      "count  4777.000000  4777.000000  4777.000000  4777.000000     4777.0   \n",
      "mean      0.027423     0.042077     0.109692     0.122462        0.0   \n",
      "std       0.163330     0.200785     0.312539     0.327853        0.0   \n",
      "min       0.000000     0.000000     0.000000     0.000000        0.0   \n",
      "25%       0.000000     0.000000     0.000000     0.000000        0.0   \n",
      "50%       0.000000     0.000000     0.000000     0.000000        0.0   \n",
      "75%       0.000000     0.000000     0.000000     0.000000        0.0   \n",
      "max       1.000000     1.000000     1.000000     1.000000        0.0   \n",
      "\n",
      "             Sport    Biography  \n",
      "count  4777.000000  4777.000000  \n",
      "mean      0.037681     0.060289  \n",
      "std       0.190442     0.238046  \n",
      "min       0.000000     0.000000  \n",
      "25%       0.000000     0.000000  \n",
      "50%       0.000000     0.000000  \n",
      "75%       0.000000     0.000000  \n",
      "max       1.000000     1.000000  \n",
      "\n",
      "[8 rows x 39 columns]\n",
      "Length after deletion: 4777\n",
      "Length before deletion: 5043\n",
      "       actor_1_facebook_likes  actor_2_facebook_likes  actor_3_facebook_likes  \\\n",
      "count             4900.000000             4898.000000             4891.000000   \n",
      "mean              6648.629796             1684.175990              653.779595   \n",
      "std              14752.996862             4090.968839             1685.449564   \n",
      "min                  0.000000                0.000000                0.000000   \n",
      "25%                623.000000                     NaN                     NaN   \n",
      "50%               1000.000000                     NaN                     NaN   \n",
      "75%              11000.000000                     NaN                     NaN   \n",
      "max             640000.000000           137000.000000            23000.000000   \n",
      "\n",
      "       aspect_ratio        budget  cast_total_facebook_likes  \\\n",
      "count   4631.000000  4.533000e+03                4900.000000   \n",
      "mean       2.128434  3.989292e+07                9849.744082   \n",
      "std        0.789307  2.065113e+08               18015.446869   \n",
      "min        1.180000  2.180000e+02                   0.000000   \n",
      "25%             NaN           NaN                1441.000000   \n",
      "50%             NaN           NaN                3143.500000   \n",
      "75%             NaN           NaN               14128.500000   \n",
      "max       16.000000  1.221550e+10              656730.000000   \n",
      "\n",
      "       director_facebook_likes     duration  facenumber_in_poster  \\\n",
      "count              4892.000000  4898.000000           4888.000000   \n",
      "mean                692.662510   108.243569              1.362725   \n",
      "std                2826.085382    22.806439              2.004185   \n",
      "min                   0.000000     7.000000              0.000000   \n",
      "25%                        NaN          NaN                   NaN   \n",
      "50%                        NaN          NaN                   NaN   \n",
      "75%                        NaN          NaN                   NaN   \n",
      "max               23000.000000   334.000000             43.000000   \n",
      "\n",
      "              gross     ...             Drama       Action  Documentary  \\\n",
      "count  4.155000e+03     ...       4900.000000  4900.000000  4900.000000   \n",
      "mean   4.851500e+07     ...          0.512041     0.230816     0.022653   \n",
      "std    6.846946e+07     ...          0.499906     0.421398     0.148810   \n",
      "min    1.620000e+02     ...          0.000000     0.000000     0.000000   \n",
      "25%             NaN     ...          0.000000     0.000000     0.000000   \n",
      "50%             NaN     ...          1.000000     0.000000     0.000000   \n",
      "75%             NaN     ...          1.000000     0.000000     0.000000   \n",
      "max    7.605058e+08     ...          1.000000     1.000000     1.000000   \n",
      "\n",
      "           Musical      History       Family      Fantasy  Game-Show  \\\n",
      "count  4900.000000  4900.000000  4900.000000  4900.000000     4900.0   \n",
      "mean      0.026939     0.041429     0.108571     0.121020        0.0   \n",
      "std       0.161921     0.199300     0.311132     0.326184        0.0   \n",
      "min       0.000000     0.000000     0.000000     0.000000        0.0   \n",
      "25%       0.000000     0.000000     0.000000     0.000000        0.0   \n",
      "50%       0.000000     0.000000     0.000000     0.000000        0.0   \n",
      "75%       0.000000     0.000000     0.000000     0.000000        0.0   \n",
      "max       1.000000     1.000000     1.000000     1.000000        0.0   \n",
      "\n",
      "             Sport    Biography  \n",
      "count  4900.000000  4900.000000  \n",
      "mean      0.036939     0.059592  \n",
      "std       0.188631     0.236753  \n",
      "min       0.000000     0.000000  \n",
      "25%       0.000000     0.000000  \n",
      "50%       0.000000     0.000000  \n",
      "75%       0.000000     0.000000  \n",
      "max       1.000000     1.000000  \n",
      "\n",
      "[8 rows x 39 columns]\n",
      "Length after deletion: 4900\n",
      "Length before deletion: 5043\n",
      "       actor_1_facebook_likes  actor_2_facebook_likes  actor_3_facebook_likes  \\\n",
      "count             4981.000000             4978.000000             4970.000000   \n",
      "mean              6558.490263             1664.347127              648.761167   \n",
      "std              14653.425810             4061.137329             1672.803600   \n",
      "min                  0.000000                0.000000                0.000000   \n",
      "25%                       NaN                     NaN                     NaN   \n",
      "50%                       NaN                     NaN                     NaN   \n",
      "75%                       NaN                     NaN                     NaN   \n",
      "max             640000.000000           137000.000000            23000.000000   \n",
      "\n",
      "       aspect_ratio        budget  cast_total_facebook_likes  \\\n",
      "count   4686.000000  4.543000e+03                4983.000000   \n",
      "mean       2.190009  3.981319e+07                9728.729681   \n",
      "std        1.216878  2.062911e+08               17895.267504   \n",
      "min        1.180000  2.180000e+02                   0.000000   \n",
      "25%             NaN           NaN                1431.000000   \n",
      "50%             NaN           NaN                3113.000000   \n",
      "75%             NaN           NaN               13890.500000   \n",
      "max       16.000000  1.221550e+10              656730.000000   \n",
      "\n",
      "       director_facebook_likes     duration  facenumber_in_poster  \\\n",
      "count              4923.000000  4977.000000           4970.000000   \n",
      "mean                688.577290   107.495680              1.371831   \n",
      "std                2817.658296    23.768233              2.016877   \n",
      "min                   0.000000     7.000000              0.000000   \n",
      "25%                        NaN          NaN                   NaN   \n",
      "50%                        NaN          NaN                   NaN   \n",
      "75%                        NaN          NaN                   NaN   \n",
      "max               23000.000000   334.000000             43.000000   \n",
      "\n",
      "              gross     ...             Drama       Action  Documentary  \\\n",
      "count  4.157000e+03     ...       4983.000000  4983.000000  4983.000000   \n",
      "mean   4.849167e+07     ...          0.513345     0.228979     0.022878   \n",
      "std    6.846124e+07     ...          0.499872     0.420218     0.149529   \n",
      "min    1.620000e+02     ...          0.000000     0.000000     0.000000   \n",
      "25%             NaN     ...          0.000000     0.000000     0.000000   \n",
      "50%             NaN     ...          1.000000     0.000000     0.000000   \n",
      "75%             NaN     ...          1.000000     0.000000     0.000000   \n",
      "max    7.605058e+08     ...          1.000000     1.000000     1.000000   \n",
      "\n",
      "           Musical      History       Family      Fantasy  Game-Show  \\\n",
      "count  4983.000000  4983.000000  4983.000000  4983.000000     4983.0   \n",
      "mean      0.026490     0.041140     0.108368     0.120811        0.0   \n",
      "std       0.160604     0.198634     0.310876     0.325940        0.0   \n",
      "min       0.000000     0.000000     0.000000     0.000000        0.0   \n",
      "25%       0.000000     0.000000     0.000000     0.000000        0.0   \n",
      "50%       0.000000     0.000000     0.000000     0.000000        0.0   \n",
      "75%       0.000000     0.000000     0.000000     0.000000        0.0   \n",
      "max       1.000000     1.000000     1.000000     1.000000        0.0   \n",
      "\n",
      "             Sport    Biography  \n",
      "count  4983.000000  4983.000000  \n",
      "mean      0.036524     0.058800  \n",
      "std       0.187609     0.235273  \n",
      "min       0.000000     0.000000  \n",
      "25%       0.000000     0.000000  \n",
      "50%       0.000000     0.000000  \n",
      "75%       0.000000     0.000000  \n",
      "max       1.000000     1.000000  \n",
      "\n",
      "[8 rows x 39 columns]\n",
      "Length after deletion: 4983\n"
     ]
    }
   ],
   "source": [
    "NA_THRESH = 4\n",
    "\n",
    "#deletes the row when there are more or equal to the threshod number of NaN's\n",
    "def remove_too_many_NaN(data, threshold):\n",
    "    print(\"Length before deletion: {}\".format(len(data)))\n",
    "\n",
    "    remove_indices = []\n",
    "    for index, nNaN in data.isnull().sum(axis=1).iteritems():\n",
    "        if nNaN >= threshold:\n",
    "            remove_indices.append(index)\n",
    "    \n",
    "    tempcopy = data.copy()\n",
    "    \n",
    "    # drop movies with too many NaNs\n",
    "    data = data.drop(data.index[remove_indices])\n",
    "    removed_films = tempcopy.drop(tempcopy.index[remove_indices])\n",
    "    \n",
    "    print(removed_films.describe())\n",
    "    print(\"Length after deletion: {}\".format(len(data)))\n",
    "    \n",
    "    return data\n",
    "\n",
    "tempcopy = movie_data.copy()\n",
    "movie_data = []\n",
    "for i in range(NUM_THRESHOLDS):\n",
    "    tempremoved = remove_too_many_NaN(tempcopy.copy(), i + 1)\n",
    "    movie_data.append(tempremoved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_num_NaNs(movie_data, marked):\n",
    "    nans = []\n",
    "    thresh = []\n",
    "    samps = []\n",
    "    for i in range(NUM_THRESHOLDS):\n",
    "        numnans = movie_data[i].isnull().sum().sum()\n",
    "        nans.append(numnans)\n",
    "        samps.append(len(movie_data[i]))\n",
    "        thresh.append(i + 1)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "#     ax = fig.add_subplot(121)\n",
    "#     plt.plot(thresh, nans, 'bx-')\n",
    "#     plt.plot(thresh[3], nans[3], 'ro')\n",
    "#     for xy in zip(thresh, nans):\n",
    "#         ax.annotate('%s' % xy[0], xy=xy, textcoords='data')\n",
    "#     plt.ylabel('Number of NaNs')\n",
    "#     plt.xlabel('Threshold')\n",
    "    \n",
    "    ax2 = fig.add_subplot(111)\n",
    "    plt.plot(thresh, samps, 'rx-')\n",
    "    plt.plot(thresh[marked], samps[marked], 'bo')\n",
    "    for xy in zip(thresh, samps):\n",
    "        ax2.annotate('%s' % xy[0], xy=xy, textcoords='data')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "plot_num_NaNs(movie_data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing Color to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def numeric_color(movie_data):\n",
    "    #replaces the color value to 1\n",
    "    movie_data.color = movie_data.color.replace(to_replace = 'Color', value = 1)\n",
    "    movie_data.color = movie_data.color.replace(to_replace = 'NaN', value = 1)\n",
    "\n",
    "    #replaces the NaN or black and white values to 0\n",
    "    for item in movie_data.color:\n",
    "        if item != 1:\n",
    "            movie_data.color = movie_data.color.replace(to_replace = item, value = 0)\n",
    "\n",
    "    #movie_data.color = new_color_column \n",
    "    #print(movie_data['color'])\n",
    "\n",
    "    #makes sure that there is nog error where it shouldn't be\n",
    "    pd.options.mode.chained_assignment= None\n",
    "    print('Done')\n",
    "    return movie_data\n",
    "\n",
    "for i in range(NUM_THRESHOLDS):\n",
    "    movie_data[i] = numeric_color(movie_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing Country to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def numeric_country(movie_data):\n",
    "    #replaces the USA values to 1\n",
    "    movie_data.country = movie_data.country.replace(to_replace ='USA', value = 1)\n",
    "    movie_data.country = movie_data.country.replace(to_replace ='NaN', value = 1)\n",
    "    #replaces the NaN or non USA values to 0\n",
    "    for item in movie_data.country:\n",
    "        if item != 1:\n",
    "            movie_data.country = movie_data.country.replace(to_replace = item, value = 0)\n",
    "\n",
    "    #print(movie_data['country'])\n",
    "\n",
    "    #makes sure that there is nog error where it shouldn't be\n",
    "    pd.options.mode.chained_assignment= None\n",
    "\n",
    "    print('Done')\n",
    "    return movie_data\n",
    "\n",
    "for i in range(NUM_THRESHOLDS):\n",
    "    movie_data[i] = numeric_country(movie_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing Languange to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def numeric_language(movie_data):\n",
    "    #replaces the English values to 1\n",
    "    movie_data.language = movie_data.language.replace(to_replace = 'English', value = 1)\n",
    "    movie_data.language = movie_data.language.replace(to_replace = 'NaN', value = 1)\n",
    "\n",
    "    #replaces the other values to 0\n",
    "    for item in movie_data.language:\n",
    "        if item != 1:\n",
    "            movie_data.language = movie_data.language.replace(to_replace = item, value = 0)\n",
    "\n",
    "    #print(movie_data['language'])\n",
    "\n",
    "    #makes sure that there is nog error where it shouldn't be\n",
    "    pd.options.mode.chained_assignment= None\n",
    "    print('Done')\n",
    "    return movie_data\n",
    "\n",
    "for i in range(NUM_THRESHOLDS):\n",
    "    movie_data[i] = numeric_language(movie_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaning Content_Rating to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def content_to_numerical(data):\n",
    "    data = data.replace(to_replace='G', value=0)\n",
    "    data = data.replace(to_replace='PG', value=12)\n",
    "    data = data.replace(to_replace='PG-13', value=13)\n",
    "    data = data.replace(to_replace='R', value=17)\n",
    "    data = data.replace(to_replace='NC-17', value=17)\n",
    "    \n",
    "    data = data.replace(to_replace='TV-PG', value=12)\n",
    "    data = data.replace(to_replace='TV-MA', value=17)\n",
    "    data = data.replace(to_replace='TV-G', value=0)\n",
    "    data = data.replace(to_replace='TV-Y', value=0)\n",
    "    data = data.replace(to_replace='TV-Y7', value=7)\n",
    "    data = data.replace(to_replace='TV-14', value=14)\n",
    "    \n",
    "    data = data.replace(to_replace='Not Rated', value=0)\n",
    "    data = data.replace(to_replace='Unrated', value=0)\n",
    "    data = data.replace(to_replace='Approved', value=0)\n",
    "    data = data.replace(to_replace='Passed', value=0)\n",
    "    \n",
    "    data = data.replace(to_replace='X', value=17)\n",
    "    data = data.replace(to_replace='M', value=17)\n",
    "    data = data.replace(to_replace='GP', value=12)\n",
    "    \n",
    "    return data\n",
    "\n",
    "for i in range(NUM_THRESHOLDS):\n",
    "    movie_data[i] = content_to_numerical(movie_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing NaNs with averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7722.74303898\n",
      "2014.86157518\n",
      "768.95332803\n",
      "2.11111376293\n",
      "46074665.6696\n",
      "11486\n",
      "804.246353752\n",
      "52410371.7385\n",
      "2003.01060727\n",
      "110.219570406\n",
      "1.37708830549\n",
      "14\n",
      "7032.59888641\n",
      "1792.34922049\n",
      "691.49108337\n",
      "2.1096122633\n",
      "41840819.2828\n",
      "10423\n",
      "744.864587973\n",
      "49287524.5918\n",
      "2001.97906459\n",
      "109.24142539\n",
      "1.35540691193\n",
      "13.7810398924\n",
      "6747.99685995\n",
      "1713.49706868\n",
      "664.698322851\n",
      "2.11774347826\n",
      "40444270.7169\n",
      "10003\n",
      "703.776847394\n",
      "48619441.8755\n",
      "2002.19866025\n",
      "108.555276382\n",
      "1.36479966436\n",
      "13.6992675571\n",
      "6648.62979592\n",
      "1684.1759902\n",
      "653.779595175\n",
      "2.1284344634\n",
      "39892924.8304\n",
      "9849\n",
      "692.662510221\n",
      "48514997.6517\n",
      "2002.39901881\n",
      "108.243568804\n",
      "1.36272504092\n",
      "13.6882617062\n",
      "6558.490263\n",
      "1664.34712736\n",
      "648.761167002\n",
      "2.19000853607\n",
      "39813189.6557\n",
      "9728\n",
      "688.57729027\n",
      "48491666.3264\n",
      "2002.45062983\n",
      "107.495680129\n",
      "1.37183098592\n",
      "13.6780054933\n"
     ]
    }
   ],
   "source": [
    "def replace_NaNs(col):\n",
    "    # compute average\n",
    "    avg = np.sum(col) / (len(col) - np.sum(col.isnull()))\n",
    "    print(avg)\n",
    "    \n",
    "    # replace NaNs with average\n",
    "    col = col.fillna(value=avg)\n",
    "    return col\n",
    "\n",
    "pd.options.mode.chained_assignment= None\n",
    "\n",
    "to_replace_NaNs = ['actor_1_facebook_likes', 'actor_2_facebook_likes', 'actor_3_facebook_likes', \n",
    "               'aspect_ratio', 'budget', 'cast_total_facebook_likes', 'director_facebook_likes','gross', 'title_year'\n",
    "                   , 'duration', 'facenumber_in_poster', 'content_rating']\n",
    "\n",
    "for i in range(NUM_THRESHOLDS):\n",
    "    for column in to_replace_NaNs:\n",
    "        movie_data[i][column] = replace_NaNs(movie_data[i][column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "# Delete columns with too little 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def del_sparse_cols(movie_data, doprint=False):\n",
    "    for genre in genres_set:\n",
    "        if doprint:\n",
    "            print(genre, ':')\n",
    "        counter = 0\n",
    "        for value in movie_data[genre]:\n",
    "            if value == 1.0:\n",
    "                counter+=1\n",
    "        \n",
    "        if doprint:\n",
    "            print(counter)\n",
    "\n",
    "    weghalen = ['Game-Show', 'News', 'Reality-TV', 'Short', 'Film-Noir']\n",
    "\n",
    "    for name in weghalen:\n",
    "        del movie_data[name]\n",
    "\n",
    "    #print(movie_data)\n",
    "    return movie_data\n",
    "\n",
    "for i in range(NUM_THRESHOLDS):\n",
    "    movie_data[i] = del_sparse_cols(movie_data[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_cor(data):\n",
    "    plt.figure(figsize=(10,10), tight_layout=True)\n",
    "    plt.pcolor(data.corr())\n",
    "    plt.yticks(np.arange(0.5, len(list(data)), 1), list(data))\n",
    "    plt.xticks(np.arange(0.5, len(list(data)), 1), list(data), rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "#plot_cor(movie_data_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainset en testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2263\n",
      "754\n",
      "754\n",
      "2694\n",
      "898\n",
      "898\n",
      "2866\n",
      "955\n",
      "956\n",
      "2940\n",
      "980\n",
      "980\n",
      "2990\n",
      "997\n",
      "996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:18: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/carlo/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:19: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/carlo/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:21: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/carlo/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:22: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/carlo/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:24: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/carlo/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:25: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "def split_to_sets(movie_data):\n",
    "    movie_data_sets = {'movie_training': 0, 'ratings_training': 0, \n",
    "                       'movie_validation': 0, 'ratings_validation': 0, \n",
    "                       'movie_test': 0, 'ratings_test': 0}\n",
    "    \n",
    "    ratings = movie_data['imdb_score'].values\n",
    "    del movie_data['imdb_score']\n",
    "\n",
    "    X = movie_data.values\n",
    "    X_std = StandardScaler().fit_transform(X)\n",
    "\n",
    "    number_of_samples = len(ratings)\n",
    "    np.random.seed(0)\n",
    "    random_indices = np.random.permutation(number_of_samples)\n",
    "    num_training_samples = round(number_of_samples*0.6)\n",
    "    num_validation_samples = round(number_of_samples*0.2)+num_training_samples\n",
    "\n",
    "    movie_data_sets['movie_training'] = X_std[random_indices[:num_training_samples]]\n",
    "    ratings_training = ratings[random_indices[:num_training_samples]]\n",
    "\n",
    "    movie_data_sets['movie_validation'] = X_std[random_indices[num_training_samples:num_validation_samples]]\n",
    "    movie_data_sets['ratings_validation'] = ratings[random_indices[num_training_samples:num_validation_samples]]\n",
    "\n",
    "    movie_data_sets['movie_test'] = X_std[random_indices[num_validation_samples:]]\n",
    "    movie_data_sets['ratings_test'] = ratings[random_indices[num_validation_samples:]]\n",
    "\n",
    "    movie_data_sets['ratings_training'] = list(ratings_training)\n",
    "\n",
    "    print(len(movie_data_sets['ratings_training']))\n",
    "    print(len(movie_data_sets['ratings_validation']))\n",
    "    print(len(movie_data_sets['ratings_test']))\n",
    "    \n",
    "    return movie_data_sets\n",
    "\n",
    "sets = []\n",
    "for i in range(NUM_THRESHOLDS):\n",
    "    sets.append(split_to_sets(movie_data[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relative_error(y_predict, y):\n",
    "    \n",
    "    error = 0\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        error += (abs(y_predict[i]-y[i]))/y[i]\n",
    "    training_error = error/len(y)*100\n",
    "    \n",
    "    return training_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analyse_predictions(regr, sets, statdict, doprint=False):\n",
    "    x_test = sets['movie_test']\n",
    "    y_test = sets['ratings_test']\n",
    "    \n",
    "    regr.fit (sets['movie_training'], sets['ratings_training'])\n",
    "\n",
    "    prediction = regr.predict(x_test)\n",
    "    results_list.append(prediction)\n",
    "\n",
    "    # The mean squared error\n",
    "    print(\"Mean squared error: %.2f\"\n",
    "          % np.mean((prediction - y_test) ** 2))\n",
    "    # Explained variance score: 1 is perfect prediction\n",
    "    print('Variance score: %.2f' % regr.score(x_test, y_test))\n",
    "\n",
    "    \n",
    "    \n",
    "    predres = list(regr.predict(x_test))\n",
    "    actual = list(y_test)\n",
    "    highest = avg = error = 0\n",
    "    lowest = predres[0]\n",
    "    for i in range(len(predres)):\n",
    "        diff = abs(predres[i] - actual[i])\n",
    "        avg += diff\n",
    "        error += abs(predres[i] - actual[i]) / actual[i]\n",
    "        \n",
    "        if doprint:\n",
    "            print(\"predicted:\", predres[i]) \n",
    "            print (\"\\tActual:\", actual[i])\n",
    "            print (\"\\tDifference:\", abs(predres[i] - actual[i]))\n",
    "\n",
    "        if diff > highest:\n",
    "            highest = diff\n",
    "        if diff < lowest:\n",
    "            lowest = diff\n",
    "\n",
    "    errper = error / len(x_test) * 100\n",
    "    avgdif =  avg / len(predres)\n",
    "    \n",
    "    if doprint:\n",
    "        #print \"Number of Samples:\", len(predres)\n",
    "        #print \"Highest difference:\", highest\n",
    "        #print \"Lowest difference:\", lowest\n",
    "        #print \"average difference:\", avgdif\n",
    "        print(\"Error Percentage:\", errper)\n",
    "    \n",
    "#     statdict['highest'].append(highest)\n",
    "#     statdict['lowest'].append(lowest)\n",
    "#     statdict['avgdif'].append(avgdif)\n",
    "    statdict['errper'].append(errper)\n",
    "    \n",
    "    return statdict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results_list = []\n",
    "statdicts = []\n",
    "for i in range(NUM_THRESHOLDS):\n",
    "    statdict = {'names':[], 'errper': [], 'predictions': []}\n",
    "    statdicts.append(statdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# def neural(statdict, sets):\n",
    "\n",
    "#     neural = MLPRegressor(hidden_layer_sizes =(100), activation = 'logistic', solver = 'adam', max_iter = 1000)\n",
    "\n",
    "#     neural.fit(sets['movie_training'], sets['ratings_training'])\n",
    "#     y_neural_train = neural.predict(sets['movie_training'])\n",
    "#     y_neural_test = neural.predict(sets['movie_test'])\n",
    "\n",
    "#     training_error = relative_error(y_neural_train, sets['ratings_training'])\n",
    "\n",
    "#     print(\"Train error = \"+'{}'.format(training_error)+\" percent\"+\" in neural network algorithm\")\n",
    "\n",
    "#     test_error = relative_error(y_neural_test,sets['ratings_test'])\n",
    "\n",
    "#     print(\"Test error = \"'{}'.format(test_error)+\" percent\"+\" in neural network algorithm\")\n",
    "    \n",
    "#     statdict['errper'].append(test_error)\n",
    "#     statdict['names'].append('neural')\n",
    "#     statdict['predictions'].append(y_neural_test)\n",
    "    \n",
    "#     return statdict\n",
    "\n",
    "# for i in range(4):\n",
    "#     statdicts[i] = neural(statdicts[i], sets[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### k-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error = 0.0 percent in knn algorithm\n",
      "Test error = 11.0490640796 percent in knn algorithm\n",
      "Train error = 0.0 percent in knn algorithm\n",
      "Test error = 11.7695538866 percent in knn algorithm\n",
      "Train error = 0.0 percent in knn algorithm\n",
      "Test error = 13.3180628211 percent in knn algorithm\n",
      "Train error = 0.0 percent in knn algorithm\n",
      "Test error = 11.8789017784 percent in knn algorithm\n",
      "Train error = 0.0 percent in knn algorithm\n",
      "Test error = 13.4150840723 percent in knn algorithm\n"
     ]
    }
   ],
   "source": [
    "def do_knn(statdict, sets, n_neighbors=5, weights='uniform'):\n",
    "        \n",
    "    neighbors = KNeighborsRegressor(n_neighbors=n_neighbors, weights=weights)\n",
    "    neighbors.fit(sets['movie_training'], sets['ratings_training'])\n",
    "    y_neighbors_train = neighbors.predict(sets['movie_training'])\n",
    "    #y_predict_train = list(y_predict_train)\n",
    "\n",
    "    train_error = relative_error(y_neighbors_train,sets['ratings_training'])\n",
    "\n",
    "    print(\"Train error = \"+'{}'.format(train_error)+\" percent\"+\" in knn algorithm\")\n",
    "\n",
    "    y_neighbors_test = neighbors.predict(sets['movie_test'])\n",
    "    #y_predict_test = list(y_predict_test)\n",
    "\n",
    "    test_error = relative_error(y_neighbors_test, sets['ratings_test'])\n",
    "\n",
    "    print(\"Test error = \"'{}'.format(test_error)+\" percent\"+\" in knn algorithm\")\n",
    "\n",
    "    statdict['errper'].append(test_error)\n",
    "    statdict['names'].append('kNN')\n",
    "    statdict['predictions'].append(y_neighbors_test)\n",
    "    \n",
    "    return statdict\n",
    "\n",
    "for i in range(NUM_THRESHOLDS):\n",
    "    statdicts[i] = do_knn(statdicts[i], sets[i], n_neighbors=15, weights='distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error = 8.18761939314\n",
      "Test error = 10.2504894917\n",
      "Train error = 8.61554189663\n",
      "Test error = 10.9147868316\n",
      "Train error = 8.69726527135\n",
      "Test error = 12.1802303446\n",
      "Train error = 9.15012885363\n",
      "Test error = 10.8586127884\n",
      "Train error = 9.089494534\n",
      "Test error = 12.6239888385\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR, NuSVR, LinearSVR\n",
    "\n",
    "def do_svr(statdict, sets):\n",
    "    svr = SVR()\n",
    "    svr.fit(sets['movie_training'], sets['ratings_training'])\n",
    "    y_svr_train = svr.predict(sets['movie_training'])\n",
    "    #y_train = list(y_train)\n",
    "\n",
    "    train_error = relative_error(y_svr_train, sets['ratings_training'])\n",
    "\n",
    "    print (\"Train error = \"+'{}'.format(train_error))\n",
    "\n",
    "    y_svr_test = svr.predict(sets['movie_test'])\n",
    "    #y_test = list(y_test)\n",
    "\n",
    "    test_error = relative_error(y_svr_test, sets['ratings_test'])\n",
    "\n",
    "    print (\"Test error = \"+'{}'.format(test_error))\n",
    "\n",
    "    statdict['errper'].append(test_error)\n",
    "    statdict['names'].append('SVM')\n",
    "    statdict['predictions'].append(y_svr_test)\n",
    "    \n",
    "    return statdict\n",
    "\n",
    "for i in range(NUM_THRESHOLDS):\n",
    "    statdicts[i] = do_svr(statdicts[i], sets[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error = 4.58320032789e-16 percent in decision trees\n",
      "Test error = 12.7494870285 percent in decision trees\n",
      "Train error = 3.99570033265e-16 percent in decision trees\n",
      "Test error = 12.7853346789 percent in decision trees\n",
      "Train error = 3.85960584977e-16 percent in decision trees\n",
      "Test error = 15.2421168132 percent in decision trees\n",
      "Train error = 3.6262701065e-16 percent in decision trees\n",
      "Test error = 14.5556956144 percent in decision trees\n",
      "Train error = 3.21821542352e-16 percent in decision trees\n",
      "Test error = 15.9788061232 percent in decision trees\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def do_dt(statdict, sets):\n",
    "    trees = DecisionTreeRegressor()\n",
    "    trees.fit(sets['movie_training'], sets['ratings_training'])\n",
    "    y_trees_train = trees.predict(sets['movie_training'])\n",
    "\n",
    "    train_error = relative_error(y_trees_train, sets['ratings_training'])\n",
    "\n",
    "    print(\"Train error = \"+'{}'.format(train_error)+\" percent\"+\" in decision trees\")\n",
    "\n",
    "    y_trees_test = trees.predict(sets['movie_test'])\n",
    "\n",
    "    test_error = relative_error(y_trees_test, sets['ratings_test'])\n",
    "\n",
    "    print(\"Test error = \"'{}'.format(test_error)+\" percent\"+\" in decision trees\")\n",
    "\n",
    "    statdict['errper'].append(test_error)\n",
    "    statdict['names'].append('DT')\n",
    "    statdict['predictions'].append(y_trees_test)\n",
    "    \n",
    "    return statdict\n",
    "\n",
    "for i in range(NUM_THRESHOLDS):\n",
    "    statdicts[i] = do_dt(statdicts[i], sets[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error = 3.74991579418 percent in random forest\n",
      "Test error = 9.65592697349 percent in random forest\n",
      "Train error = 3.84112146637 percent in random forest\n",
      "Test error = 10.4696613313 percent in random forest\n",
      "Train error = 3.83879011846 percent in random forest\n",
      "Test error = 11.585416384 percent in random forest\n",
      "Train error = 4.07255438128 percent in random forest\n",
      "Test error = 10.3726434466 percent in random forest\n",
      "Train error = 3.98916798064 percent in random forest\n",
      "Test error = 11.9113992217 percent in random forest\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, ExtraTreesRegressor\n",
    "\n",
    "def do_randforest(statdict, sets):\n",
    "    random_forest = RandomForestRegressor(n_estimators = 20)\n",
    "    random_forest.fit(sets['movie_training'], sets['ratings_training'])\n",
    "    y_forest_train = random_forest.predict(sets['movie_training'])\n",
    "\n",
    "    train_error = relative_error(y_forest_train, sets['ratings_training'])\n",
    "\n",
    "    print(\"Train error = \"+'{}'.format(train_error)+\" percent\"+\" in random forest\")\n",
    "\n",
    "    y_forest_test = random_forest.predict(sets['movie_test'])\n",
    "\n",
    "    test_error = relative_error(y_forest_test, sets['ratings_test'])\n",
    "\n",
    "    print(\"Test error = \"'{}'.format(test_error)+\" percent\"+\" in random forest\")\n",
    "\n",
    "    statdict['errper'].append(test_error)\n",
    "    statdict['names'].append('Rfor')\n",
    "    statdict['predictions'].append(y_forest_test)\n",
    "    \n",
    "    return statdict\n",
    "\n",
    "for i in range(NUM_THRESHOLDS):\n",
    "    statdicts[i] = do_randforest(statdicts[i], sets[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extremely randomized trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error = 1.78290737788e-14 percent in random forest\n",
      "Test error = 9.85663010793 percent in random forest\n",
      "Train error = 1.79560596013e-14 percent in random forest\n",
      "Test error = 9.94806382859 percent in random forest\n",
      "Train error = 1.7969048602e-14 percent in random forest\n",
      "Test error = 11.3981722939 percent in random forest\n",
      "Train error = 1.82570907715e-14 percent in random forest\n",
      "Test error = 10.3682213633 percent in random forest\n",
      "Train error = 1.80387669471e-14 percent in random forest\n",
      "Test error = 11.8069570457 percent in random forest\n"
     ]
    }
   ],
   "source": [
    "def do_xrandtrees(statdict, sets):\n",
    "    extra = ExtraTreesRegressor(n_estimators = 20)\n",
    "    extra.fit(sets['movie_training'], sets['ratings_training'])\n",
    "    y_extra_train = extra.predict(sets['movie_training'])\n",
    "\n",
    "    train_error = relative_error(y_extra_train, sets['ratings_training'])\n",
    "\n",
    "    print(\"Train error = \"+'{}'.format(train_error)+\" percent\"+\" in random forest\")\n",
    "\n",
    "    y_extra_test = extra.predict(sets['movie_test'])\n",
    "\n",
    "    test_error = relative_error(y_extra_test, sets['ratings_test'])\n",
    "\n",
    "    print(\"Test error = \"'{}'.format(test_error)+\" percent\"+\" in random forest\")\n",
    "\n",
    "    statdict['errper'].append(test_error)\n",
    "    statdict['names'].append('XRfor')\n",
    "    statdict['predictions'].append(y_extra_test)\n",
    "    \n",
    "    return statdict\n",
    "\n",
    "for i in range(NUM_THRESHOLDS):\n",
    "    statdicts[i] = do_xrandtrees(statdicts[i], sets[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_baggingregr(statdict, sets):\n",
    "    #regressor  = BaggingRegressor(MLPRegressor(max_iter = 300))\n",
    "    bagging = BaggingRegressor(RandomForestRegressor())\n",
    "    bagging.fit(sets['movie_training'], sets['ratings_training'])\n",
    "    y_bagging_train = bagging.predict(sets['movie_training'])\n",
    "    #y_predict_train = list(y_predict_train)\n",
    "\n",
    "    train_error = relative_error(y_bagging_train ,sets['ratings_training'])\n",
    "\n",
    "    print(\"Train error = \"+'{}'.format(train_error)+\" percent\"+\" in random forest\")\n",
    "\n",
    "    y_bagging_test = bagging.predict(sets['movie_test'])\n",
    "    #y_predict_test = list(y_predict_test)\n",
    "\n",
    "    test_error = relative_error(y_bagging_test, sets['ratings_test'])\n",
    "\n",
    "    print(\"Test error = \"'{}'.format(test_error)+\" percent\"+\" in random forest\")\n",
    "\n",
    "    statdict['errper'].append(test_error)\n",
    "    statdict['names'].append('bag')\n",
    "    statdict['predictions'].append(y_bagging_test)\n",
    "    \n",
    "    return statdict\n",
    "\n",
    "# for i in range(4):\n",
    "#     statdicts[i] = do_baggingregr(statdicts[i], sets[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural networks and svr and random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.26095830924\n",
      "0.0969387755102\n",
      "9.89242904216\n",
      "0.115306122449\n",
      "11.1864289399\n",
      "0.14387755102\n",
      "10.0285407066\n",
      "0.163265306122\n",
      "11.5240013927\n",
      "0.165306122449\n"
     ]
    }
   ],
   "source": [
    "def do_ensemble(statdict, sets):\n",
    "    y_svr_test = statdict['predictions'][statdict['names'].index('SVM')]\n",
    "    y_forest_test = statdict['predictions'][statdict['names'].index('Rfor')]\n",
    "    y_extra_test = statdict['predictions'][statdict['names'].index('XRfor')]\n",
    "    ratings_test = sets['ratings_test']\n",
    "\n",
    "\n",
    "    prediction = [sum(x)/3 for x in zip(y_svr_test, y_forest_test, y_extra_test)]\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(len(prediction)):\n",
    "        if abs(prediction[i]-ratings_test[i])>1.0:\n",
    "            counter+= 1\n",
    "            #print(prediction[i], ratings_test[i])\n",
    "\n",
    "    error_ensemble = relative_error(prediction, ratings_test)\n",
    "\n",
    "    statdict['errper'].append(error_ensemble)\n",
    "    statdict['names'].append('ensemble')\n",
    "    statdict['predictions'].append(prediction)\n",
    "\n",
    "    print(error_ensemble)\n",
    "    print(counter/980.0)\n",
    "    \n",
    "    return statdict\n",
    "\n",
    "for i in range(NUM_THRESHOLDS):\n",
    "    statdicts[i] = do_ensemble(statdicts[i], sets[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(movie_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# movie_data['color'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.69\n",
      "Variance score: 0.37\n",
      "Mean squared error: 0.69\n",
      "Variance score: 0.38\n",
      "Mean squared error: 0.68\n",
      "Variance score: 0.39\n",
      "Mean squared error: 0.67\n",
      "Variance score: 0.39\n",
      "Mean squared error: 0.72\n",
      "Variance score: 0.41\n",
      "Mean squared error: 0.72\n",
      "Variance score: 0.41\n",
      "Mean squared error: 0.72\n",
      "Variance score: 0.41\n",
      "Mean squared error: 0.72\n",
      "Variance score: 0.41\n",
      "Mean squared error: 0.87\n",
      "Variance score: 0.34\n",
      "Mean squared error: 0.87\n",
      "Variance score: 0.33\n",
      "Mean squared error: 0.88\n",
      "Variance score: 0.33\n",
      "Mean squared error: 0.88\n",
      "Variance score: 0.33\n",
      "Mean squared error: 0.77\n",
      "Variance score: 0.38\n",
      "Mean squared error: 0.77\n",
      "Variance score: 0.38\n",
      "Mean squared error: 0.78\n",
      "Variance score: 0.38\n",
      "Mean squared error: 0.78\n",
      "Variance score: 0.38\n",
      "Mean squared error: 0.96\n",
      "Variance score: 0.31\n",
      "Mean squared error: 0.96\n",
      "Variance score: 0.31\n",
      "Mean squared error: 0.96\n",
      "Variance score: 0.31\n",
      "Mean squared error: 0.96\n",
      "Variance score: 0.31\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def do_linear_models(statdict, sets):\n",
    "    regr = linear_model.LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
    "\n",
    "    statdict = analyse_predictions(regr, sets, statdict)\n",
    "    statdict['names'].append('linreg')\n",
    "\n",
    "\n",
    "    regr = linear_model.Ridge()\n",
    "    statdict = analyse_predictions(regr, sets, statdict)\n",
    "    statdict['names'].append('ridgereg')\n",
    "\n",
    "\n",
    "    regr = linear_model.Lasso(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=1000000,\n",
    "       normalize=False, positive=False, precompute=False, random_state=None,\n",
    "       selection='cyclic', tol=0.0001, warm_start=False)\n",
    "    statdict = analyse_predictions(regr, sets, statdict)\n",
    "    statdict['names'].append('lassoreg')\n",
    "\n",
    "\n",
    "    regr = linear_model.BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
    "           fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
    "           normalize=False, tol=0.001, verbose=False)\n",
    "    statdict = analyse_predictions(regr, sets, statdict)\n",
    "    statdict['names'].append('bayesian')\n",
    "    \n",
    "    return statdict\n",
    "\n",
    "\n",
    "for i in range(NUM_THRESHOLDS):\n",
    "    statdicts[i] = do_linear_models(statdicts[i], sets[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_threshold(statdicts):\n",
    "    n_groups = len(statdicts[0]['names'])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(10, 5)\n",
    "    \n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.9 * (1.0 / len(statdicts))\n",
    "\n",
    "    opacity = 0.4\n",
    "    error_config = {'ecolor': '0.3'}\n",
    "\n",
    "    colors = ['b', 'g', 'r', 'c', 'm', 'k', 'y', 'w', 'b', 'g', 'r', 'c', 'm', 'k', 'y', 'w']\n",
    "    for i in range(len(statdicts)):\n",
    "        rects1 = plt.bar(index + bar_width * i, statdicts[i]['errper'], bar_width,\n",
    "                         alpha=opacity,\n",
    "                         color=colors[i],\n",
    "                         error_kw=error_config,\n",
    "                         label=\"threshold {}\".format(i + 1))\n",
    "    plt.xlabel('Algorithm')\n",
    "    plt.ylabel('Error Percentages (in %)')\n",
    "    plt.title('Error Percentages for various algorithms depending on the threshold')\n",
    "    plt.xticks(index + bar_width * 2, statdict['names'], rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.legend(bbox_to_anchor=(0, 0.3), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "    \n",
    "plot_threshold(statdicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_errors(statdict):\n",
    "    n_groups = len(statdict['names'])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.9\n",
    "\n",
    "    opacity = 0.4\n",
    "    error_config = {'ecolor': '0.3'}\n",
    "\n",
    "    rects1 = plt.bar(index, statdict['errper'], bar_width,\n",
    "                     alpha=opacity,\n",
    "                     color='r',\n",
    "                     error_kw=error_config)\n",
    "\n",
    "    plt.xlabel('Algorithm')\n",
    "    plt.ylabel('Error Percentages (in %)')\n",
    "    plt.title('Error Percentages for various algorithms using threshold 4')\n",
    "    plt.xticks(index + bar_width * 0.5, statdict['names'], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_errors(statdicts[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_algorithm(statdicts, algorithm):\n",
    "    n_groups = NUM_THRESHOLDS\n",
    "\n",
    "    errpers = []\n",
    "    algind = statdicts[0]['names'].index(algorithm)\n",
    "    for t in range(n_groups):\n",
    "        errpers.append(statdicts[t]['errper'][algind])\n",
    "        \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.9\n",
    "\n",
    "    opacity = 0.4\n",
    "    error_config = {'ecolor': '0.3'}\n",
    "\n",
    "    rects1 = plt.bar(index, errpers, bar_width,\n",
    "                     alpha=opacity,\n",
    "                     color='r',\n",
    "                     error_kw=error_config)\n",
    "\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Error Percentages (in %)')\n",
    "    plt.title('Error Percentages for algorithm \\'{}\\' with varying thresholds'.format(algorithm))\n",
    "    plt.xticks(index + bar_width * 0.5, range(1, n_groups + 1))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_algorithm(statdicts, 'ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
