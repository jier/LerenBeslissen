{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name MLPRegressor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8429fafc6b71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKNeighborsRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMLPRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name MLPRegressor"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "#reads in the data\n",
    "data = pd.read_csv('movie_metadata.csv')\n",
    "\n",
    "#removes the values that aren't numeric\n",
    "to_drop = ['director_name', 'num_critic_for_reviews', 'actor_2_name','actor_1_name', 'movie_title', 'num_voted_users'\n",
    "           , 'actor_3_name', 'plot_keywords', 'movie_imdb_link', 'num_user_for_reviews', 'content_rating']\n",
    "\n",
    "#makes the new data set without the to_drop colums\n",
    "features_list = data.columns.difference(to_drop)\n",
    "movie_data = data[features_list]\n",
    "#print(np.sum(movie_num.isnull()))\n",
    "#print(movie_data.content_rating.unique())\n",
    "pd.options.mode.chained_assignment = None \n",
    "   \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing Genres into individual Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['Sci-Fi', 'Crime', 'Romance', 'Animation', 'Music', 'Comedy', 'War', 'Horror', 'Film-Noir', 'Adventure', 'News', 'Reality-TV', 'Thriller', 'Western', 'Mystery', 'Short', 'Drama', 'Action', 'Documentary', 'Musical', 'History', 'Family', 'Fantasy', 'Game-Show', 'Sport', 'Biography'])\n"
     ]
    }
   ],
   "source": [
    "genres = []\n",
    "\n",
    "for string in movie_data['genres']:\n",
    "    genre = string.split('|')\n",
    "    genres = genres+genre\n",
    "    \n",
    "genres_set = set(genres)\n",
    "print(genres_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "genres_dict = dict()\n",
    "for genre in genres_set:\n",
    "    genres_dict[genre] = []\n",
    "    \n",
    "for string in movie_data.genres:\n",
    "    genres = string.split('|')\n",
    "    for genre in genres_set:\n",
    "        if genre in genres:\n",
    "            genres_dict[genre] = genres_dict[genre]+[1]\n",
    "        else:\n",
    "            genres_dict[genre] = genres_dict[genre]+[0]\n",
    "\n",
    "del movie_data['genres']\n",
    "#print(genres_dict['Short'])\n",
    "\n",
    "for genre in genres_set:\n",
    "    series = pd.Series(genres_dict[genre])\n",
    "    movie_data[genre] = series\n",
    "\n",
    "#print(movie_data['Short'].values)    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting NaN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length before deletion: 5043\n",
      "Length after deletion: 4927\n"
     ]
    }
   ],
   "source": [
    "NA_THRESH = 4\n",
    "\n",
    "#deletes the row when there are more or equal to the threshod number of NaN's\n",
    "def remove_too_many_NaN(data, threshold):\n",
    "    print(\"Length before deletion: {}\".format(len(data)))\n",
    "\n",
    "    remove_indices = []\n",
    "    for index, nNaN in data.isnull().sum(axis=1).iteritems():\n",
    "        if nNaN >= threshold:\n",
    "            remove_indices.append(index)\n",
    "    \n",
    "    # drop movies with too many NaNs\n",
    "    data = data.drop(data.index[remove_indices])\n",
    "    print(\"Length after deletion: {}\".format(len(data)))\n",
    "    \n",
    "    return data\n",
    "\n",
    "#returns length\n",
    "movie_data = remove_too_many_NaN(movie_data, NA_THRESH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def replace_NaNs(col):\n",
    "    # compute average\n",
    "    avg = np.sum(col) / (len(col) - np.sum(col.isnull()))\n",
    "    \n",
    "    # replace NaNs with average\n",
    "    col = col.fillna(value=avg)\n",
    "    return col\n",
    "\n",
    "pd.options.mode.chained_assignment= None\n",
    "\n",
    "to_replace_NaNs = ['actor_1_facebook_likes', 'actor_2_facebook_likes', 'actor_3_facebook_likes', \n",
    "               'aspect_ratio', 'budget', 'cast_total_facebook_likes', 'director_facebook_likes', 'gross', 'title_year'\n",
    "                   , 'duration', 'facenumber_in_poster']\n",
    "for column in to_replace_NaNs:\n",
    "    movie_data[column] = replace_NaNs(movie_data[column])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing Color to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#replaces the color value to 1\n",
    "movie_data.color = movie_data.color.replace(to_replace = 'Color', value = 1)\n",
    "movie_data.color = movie_data.color.replace(to_replace = 'NaN', value = 1)\n",
    "\n",
    "#replaces the NaN or black and white values to 0\n",
    "for item in movie_data.color:\n",
    "    if item != 1:\n",
    "        movie_data.color = movie_data.color.replace(to_replace = item, value = 0)\n",
    "        \n",
    "#movie_data.color = new_color_column \n",
    "#print(movie_data['color'])\n",
    "\n",
    "#makes sure that there is nog error where it shouldn't be\n",
    "pd.options.mode.chained_assignment= None\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing Country to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#replaces the USA values to 1\n",
    "movie_data.country = movie_data.country.replace(to_replace ='USA', value = 1)\n",
    "movie_data.country = movie_data.country.replace(to_replace ='NaN', value = 1)\n",
    "#replaces the NaN or non USA values to 0\n",
    "for item in movie_data.country:\n",
    "    if item != 1:\n",
    "        movie_data.country = movie_data.country.replace(to_replace = item, value = 0)\n",
    "       \n",
    "#print(movie_data['country'])\n",
    "\n",
    "#makes sure that there is nog error where it shouldn't be\n",
    "pd.options.mode.chained_assignment= None\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing Languange to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#replaces the English values to 1\n",
    "movie_data.language = movie_data.language.replace(to_replace = 'English', value = 1)\n",
    "movie_data.language = movie_data.language.replace(to_replace = 'NaN', value = 1)\n",
    "\n",
    "#replaces the other values to 0\n",
    "for item in movie_data.language:\n",
    "    if item != 1:\n",
    "        movie_data.language = movie_data.language.replace(to_replace = item, value = 0)\n",
    "        \n",
    "#print(movie_data['language'])\n",
    "\n",
    "#makes sure that there is nog error where it shouldn't be\n",
    "pd.options.mode.chained_assignment= None\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove columns with a low amount of 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for genre in genres_set:\n",
    "    counter = 0\n",
    "    for value in movie_data[genre]:\n",
    "        if value == 1.0:\n",
    "            counter+=1\n",
    "    \n",
    "weghalen = ['Game-Show', 'News', 'Reality-TV', 'Short', 'Film-Noir']\n",
    "\n",
    "for name in weghalen:\n",
    "    del movie_data[name]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaning Content_Rating to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def content_to_numerical(data):\n",
    "    data = data.replace(to_replace='G', value=0)\n",
    "    data = data.replace(to_replace='PG', value=12)\n",
    "    data = data.replace(to_replace='PG-13', value=13)\n",
    "    data = data.replace(to_replace='R', value=17)\n",
    "    data = data.replace(to_replace='NC-17', value=17)\n",
    "    \n",
    "    data = data.replace(to_replace='TV-PG', value=12)\n",
    "    data = data.replace(to_replace='TV-MA', value=17)\n",
    "    data = data.replace(to_replace='TV-G', value=0)\n",
    "    data = data.replace(to_replace='TV-Y', value=0)\n",
    "    data = data.replace(to_replace='TV-Y7', value=7)\n",
    "    data = data.replace(to_replace='TV-14', value=14)\n",
    "    \n",
    "    data = data.replace(to_replace='Not Rated', value=0)\n",
    "    data = data.replace(to_replace='Unrated', value=0)\n",
    "    data = data.replace(to_replace='Approved', value=0)\n",
    "    data = data.replace(to_replace='Passed', value=0)\n",
    "    \n",
    "    data = data.replace(to_replace='X', value=17)\n",
    "    data = data.replace(to_replace='M', value=17)\n",
    "    data = data.replace(to_replace='GP', value=12)\n",
    "    \n",
    "    return data\n",
    "\n",
    "movie_data = content_to_numerical(movie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainset en testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings = movie_data['imdb_score'].values\n",
    "del movie_data['imdb_score']\n",
    "\n",
    "X = movie_data.values\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "\n",
    "number_of_samples = len(ratings)\n",
    "np.random.seed(0)\n",
    "random_indices = np.random.permutation(number_of_samples)\n",
    "num_training_samples = int(number_of_samples*0.75)\n",
    "x_train = X_std[random_indices[:num_training_samples]]\n",
    "y_train = ratings[random_indices[:num_training_samples]]\n",
    "\n",
    "\n",
    "x_test = X_std[random_indices[num_training_samples:]]\n",
    "y_test = ratings[random_indices[num_training_samples:]]\n",
    "y_train = list(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analyse_predictions(regr, x_test, y_test, statdict, doprint=False):\n",
    "    regr.fit (x_train, y_train)\n",
    "\n",
    "    prediction = regr.predict(x_test)\n",
    "    results_list.append(prediction)\n",
    "\n",
    "    # The mean squared error\n",
    "    print(\"Mean squared error: %.2f\"\n",
    "          % np.mean((prediction - y_test) ** 2))\n",
    "    # Explained variance score: 1 is perfect prediction\n",
    "    print('Variance score: %.2f' % regr.score(x_test, y_test))\n",
    "\n",
    "    \n",
    "    \n",
    "    predres = list(regr.predict(x_test))\n",
    "    actual = list(y_test)\n",
    "    highest = avg = error = 0\n",
    "    lowest = predres[0]\n",
    "    for i in range(len(predres)):\n",
    "        diff = abs(predres[i] - actual[i])\n",
    "        avg += diff\n",
    "        error += abs(predres[i] - actual[i]) / actual[i]\n",
    "        \n",
    "        if doprint:\n",
    "            print \"predicted:\", predres[i], \n",
    "            print \"\\tActual:\", actual[i],\n",
    "            print \"\\tDifference:\", abs(predres[i] - actual[i])\n",
    "\n",
    "        if diff > highest:\n",
    "            highest = diff\n",
    "        if diff < lowest:\n",
    "            lowest = diff\n",
    "\n",
    "    errper = error / len(x_test) * 100\n",
    "    avgdif =  avg / len(predres)\n",
    "    \n",
    "    print \"Number of Samples:\", len(predres)\n",
    "    print \"Highest difference:\", highest\n",
    "    print \"Lowest difference:\", lowest\n",
    "    print \"average difference:\", avgdif\n",
    "    print \"Error Percentage:\", errper\n",
    "    \n",
    "    statdict['highest'].append(highest)\n",
    "    statdict['lowest'].append(lowest)\n",
    "    statdict['avgdif'].append(avgdif)\n",
    "    statdict['errper'].append(errper)\n",
    "    \n",
    "    return statdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable set-up for result combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_list = []\n",
    "\n",
    "statdict = {'errper': [], 'avgdif': [], 'highest': [], 'lowest': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.87\n",
      "Variance score: 0.31\n",
      "Number of Samples: 1232\n",
      "Highest difference: 6.32301115636\n",
      "Lowest difference: 0.000866318916382\n",
      "average difference: 0.688542498759\n",
      "Error Percentage: 12.9372047994\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "regr = linear_model.LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
    "\n",
    "statdict = analyse_predictions(regr, x_test, y_test, statdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.87\n",
      "Variance score: 0.31\n",
      "Number of Samples: 1232\n",
      "Highest difference: 6.32035105392\n",
      "Lowest difference: 0.00156514727646\n",
      "average difference: 0.688613770531\n",
      "Error Percentage: 12.9382903956\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.Ridge()\n",
    "\n",
    "statdict = analyse_predictions(regr, x_test, y_test, statdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.87\n",
      "Variance score: 0.31\n",
      "Number of Samples: 1232\n",
      "Highest difference: 6.30663703204\n",
      "Lowest difference: 0.000677759640084\n",
      "average difference: 0.688939790889\n",
      "Error Percentage: 12.9437323438\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.Lasso(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=1000000,\n",
    "   normalize=False, positive=False, precompute=False, random_state=None,\n",
    "   selection='cyclic', tol=0.0001, warm_start=False)\n",
    "\n",
    "statdict = analyse_predictions(regr, x_test, y_test, statdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.87\n",
      "Variance score: 0.31\n",
      "Number of Samples: 1232\n",
      "Highest difference: 6.27513098687\n",
      "Lowest difference: 0.000361503201298\n",
      "average difference: 0.688908500637\n",
      "Error Percentage: 12.9470735163\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
    "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
    "       normalize=False, tol=0.001, verbose=False)\n",
    "\n",
    "statdict = analyse_predictions(regr, x_test, y_test, statdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.81\n",
      "Variance score: 0.36\n",
      "Number of Samples: 1232\n",
      "Highest difference: 5.22826008521\n",
      "Lowest difference: 0.0\n",
      "average difference: 0.669750525595\n",
      "Error Percentage: 12.2608466752\n"
     ]
    }
   ],
   "source": [
    "regr = KNeighborsRegressor(n_neighbors=15, weights='distance')\n",
    "\n",
    "statdict = analyse_predictions(regr, x_test, y_test, statdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 1.29\n",
      "Variance score: -0.01\n",
      "Number of Samples: 1232\n",
      "Highest difference: 5.9\n",
      "Lowest difference: 0.0\n",
      "average difference: 0.822077922078\n",
      "Error Percentage: 14.9597459319\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regr = DecisionTreeRegressor()\n",
    "\n",
    "statdict = analyse_predictions(regr, x_test, y_test, statdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 1232\n",
      "Highest difference: 6.05889838574\n",
      "Lowest difference: 0\n",
      "average difference: 0.643066458155\n",
      "Error Percentage: 12.1397935736\n"
     ]
    }
   ],
   "source": [
    "combo_results = []\n",
    "n_algorithms = len(results_list)\n",
    "for i in range(len(results_list[0])):\n",
    "    tot = 0.0\n",
    "    for a in range(n_algorithms):\n",
    "        tot += results_list[a][i]\n",
    "    combo_results.append(tot / n_algorithms)\n",
    "\n",
    "predres = combo_results\n",
    "actual = list(y_test)\n",
    "highest = lowest = avg = error = 0\n",
    "for i in range(len(predres)):\n",
    "    diff = abs(predres[i] - actual[i])\n",
    "    avg += diff\n",
    "    error += abs(predres[i] - actual[i]) / actual[i]\n",
    "\n",
    "    if False:\n",
    "        print \"predicted:\", predres[i], \n",
    "        print \"\\tActual:\", actual[i],\n",
    "        print \"\\tDifference:\", abs(predres[i] - actual[i])\n",
    "\n",
    "    if diff > highest:\n",
    "        highest = diff\n",
    "    if diff < lowest:\n",
    "        lowest = diff\n",
    "\n",
    "errper = error / len(x_test) * 100\n",
    "avgdif = avg / len(predres)\n",
    "print \"Number of Samples:\", len(predres)\n",
    "print \"Highest difference:\", highest\n",
    "print \"Lowest difference:\", lowest\n",
    "print \"average difference:\", avgdif\n",
    "print \"Error Percentage:\", errper\n",
    "\n",
    "statdict['highest'].append(highest)\n",
    "statdict['lowest'].append(lowest)\n",
    "statdict['avgdif'].append(avgdif)\n",
    "statdict['errper'].append(errper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_groups = 7\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.9\n",
    "\n",
    "opacity = 0.4\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "rects1 = plt.bar(index, statdict['errper'], bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='b',\n",
    "                 error_kw=error_config)\n",
    "\n",
    "plt.xlabel('Regression Algorithm')\n",
    "plt.ylabel('Error Percentages (in %)')\n",
    "plt.title('Error Percentages for various regression algorithms')\n",
    "plt.xticks(index + bar_width / 2, ('LinRegr', 'RidRegr', 'Lasso', \n",
    "                                   'Bayesian', 'kNN', 'DT', 'Combo'))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
